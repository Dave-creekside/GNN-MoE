{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "u8x17zlSzp8q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7205941e-b806-433b-b659-c2645caea15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "Found existing installation: datasets 2.14.4\n",
      "Uninstalling datasets-2.14.4:\n",
      "  Successfully uninstalled datasets-2.14.4\n",
      "Found existing installation: fsspec 2025.3.2\n",
      "Uninstalling fsspec-2025.3.2:\n",
      "  Successfully uninstalled fsspec-2025.3.2\n",
      "Found existing installation: huggingface-hub 0.32.2\n",
      "Uninstalling huggingface-hub-0.32.2:\n",
      "  Successfully uninstalled huggingface-hub-0.32.2\n",
      "Found existing installation: transformers 4.52.3\n",
      "Uninstalling transformers-4.52.3:\n",
      "  Successfully uninstalled transformers-4.52.3\n",
      "Found existing installation: tokenizers 0.21.1\n",
      "Uninstalling tokenizers-0.21.1:\n",
      "  Successfully uninstalled tokenizers-0.21.1\n",
      "Collecting datasets==2.14.7\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fsspec==2023.10.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting huggingface_hub==0.17.3\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers==4.35.2\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers==0.15.0\n",
      "  Downloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (18.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.14.7)\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (3.11.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.14.7) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.17.3) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.17.3) (4.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.14.7) (1.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.7) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.7) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.7) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.14.7) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.7) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.14.7) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.7) (1.17.0)\n",
      "Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: pyarrow-hotfix, fsspec, huggingface_hub, tokenizers, transformers, datasets\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio-client 1.10.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "diffusers 0.33.1 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.10.0 which is incompatible.\n",
      "sentence-transformers 4.1.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.2 which is incompatible.\n",
      "accelerate 1.7.0 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.14.7 fsspec-2023.10.0 huggingface_hub-0.17.3 pyarrow-hotfix-0.7 tokenizers-0.15.0 transformers-4.35.2\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch datasets numpy matplotlib seaborn\n",
    "!pip uninstall -y datasets fsspec huggingface_hub transformers tokenizers\n",
    "!rm -rf ~/.cache/huggingface/datasets\n",
    "!pip install datasets==2.14.7 fsspec==2023.10.0 huggingface_hub==0.17.3 transformers==4.35.2 tokenizers==0.15.0\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_493nvLi32n"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "IXQNwA_X4FcH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "dd6fcf2b-214e-4556-c944-ae25bcdd24ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_cluster-1.6.3%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
      "Successfully installed pyg_lib-0.4.0+pt26cu124 torch_cluster-1.6.3+pt26cu124 torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124 torch_spline_conv-1.2.2+pt26cu124\n"
     ]
    }
   ],
   "source": [
    "#print(torch.__version__)\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuvohLe0Mqd8"
   },
   "source": [
    "<h1>Optimized Test Runs</h1>\n",
    "\n",
    "> Add blockquote\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "B2AMEeBWd9LL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5c03ca49-1d7c-46bb-f9d7-c659a857eaf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/libpyg.so: undefined symbol: _ZNK3c1011StorageImpl27throw_data_ptr_access_errorEv\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_St8optionalISt17basic_string_viewIcSt11char_traitsIcEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_basis_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorEb\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorEb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Adjusting num_heads from 8 to 4 based on embed_dim 256\n",
      "Adjusting num_heads from 8 to 4 based on embed_dim 256\n",
      "Overriding config.embed_dim with CLI arg: 512\n",
      "Overriding config.num_layers with CLI arg: 6\n",
      "Overriding config.num_experts with CLI arg: 6\n",
      "Overriding config.coupler_type with CLI arg: HGNN\n",
      "Overriding config.static_hyperedge_strategy with CLI arg: all_triplets\n",
      "Overriding config.orthogonality_loss_weight with CLI arg: 0.15\n",
      "Overriding config.orthogonality_warmup_steps with CLI arg: 100\n",
      "Overriding config.learning_rate with CLI arg: 0.0003\n",
      "Overriding config.epochs with CLI arg: 5\n",
      "Overriding config.max_batches_per_epoch with CLI arg: 200\n",
      "Overriding config.eval_every with CLI arg: 50\n",
      "📁 Created checkpoint directory: checkpoints/orthogonal_a100_large\n",
      "===== GNN-MoE Hyperparameter Script Execution Started =====\n",
      "Run Name: orthogonal_a100_large\n",
      "Effective Config: GNNMoEConfig(vocab_size=50257, max_seq_length=128, embed_dim=512, num_layers=6, num_heads=4, dropout_rate=0.1, num_experts=6, gnn_layers=2, batch_size=32, learning_rate=0.0003, epochs=5, max_batches_per_epoch=200, eval_every=50, dataset_name='wikitext', dataset_config_name='wikitext-2-v1', num_train_samples=-1, num_eval_samples=-1, checkpoint_dir='checkpoints/orthogonal_a100_large', resume_checkpoint=None, run_name='orthogonal_a100_large', seed=42, num_workers_dataloader=2, coupler_type='HGNN', hgnn_conv_type='HypergraphConv', static_hyperedge_strategy='all_triplets', hgnn_learnable_edge_weights=True, apply_orthogonality_loss=True, orthogonality_loss_weight=0.15, orthogonality_aggregation='mean', orthogonality_loss_type='gram_identity', orthogonality_warmup_steps=100, track_expert_specialization=True)\n",
      "🚀 Device: CUDA (Available: 1)\n",
      "📁 Created 'plots' directory for output visualizations.\n",
      "✅ Environment ready. Seed: 42, Device: cuda\n",
      "🚀 Setting up data loading for wikitext / wikitext-2-v1...\n",
      "Downloading tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 195kB/s]\n",
      "Downloading config.json: 100% 665/665 [00:00<00:00, 5.55MB/s]\n",
      "Downloading vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.54MB/s]\n",
      "Downloading merges.txt: 100% 456k/456k [00:00<00:00, 3.89MB/s]\n",
      "Downloading tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 7.57MB/s]\n",
      "📦 Attempting wikitext (wikitext-2-v1) dataset loading...\n",
      "Downloading readme: 100% 10.5k/10.5k [00:00<00:00, 38.0MB/s]\n",
      "Downloading data files:   0% 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0% 0.00/685k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 685k/685k [00:00<00:00, 2.40MB/s]\n",
      "Downloading data files:  33% 1/3 [00:00<00:00,  3.47it/s]\n",
      "Downloading data:   0% 0.00/6.07M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 6.07M/6.07M [00:00<00:00, 22.9MB/s]\n",
      "Downloading data files:  67% 2/3 [00:00<00:00,  3.63it/s]\n",
      "Downloading data:   0% 0.00/618k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 618k/618k [00:00<00:00, 3.09MB/s]\n",
      "Downloading data files: 100% 3/3 [00:00<00:00,  3.96it/s]\n",
      "Extracting data files: 100% 3/3 [00:00<00:00, 2171.34it/s]\n",
      "Generating test split: 100% 4358/4358 [00:00<00:00, 96552.18 examples/s]\n",
      "Generating train split: 100% 36718/36718 [00:00<00:00, 744514.05 examples/s]\n",
      "Generating validation split: 100% 3760/3760 [00:00<00:00, 687710.76 examples/s]\n",
      "Raw lines >30 chars: Train 18131, Eval 1913\n",
      "✅ SUCCESS: Real wikitext-2-v1 data loaded!\n",
      "\n",
      "✅ DATA LOADING COMPLETE!\n",
      "🎯 Mode: REAL_WIKITEXT_2_V1\n",
      "📊 Train samples: 18131, Eval samples: 1913\n",
      "📦 Train batches: 567, Eval batches: 60\n",
      "🔤 Vocabulary: 50,257 tokens (using gpt2)\n",
      "\n",
      "🏗️ Creating GNN-MoE Model with effective vocab_size: 50257\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "\n",
      "🚀 Starting/Resuming HGNN-MoE Training on cuda\n",
      "📊 Model: 169,799,881 parameters\n",
      "🎯 Training: 5 epochs × 200 batches/epoch = 1000 total steps\n",
      "💾 Checkpoints will be saved in: checkpoints/orthogonal_a100_large\n",
      "Epoch 1/5:  24% 49/200 [05:15<15:48,  6.28s/it, total=73.4795, lm=10.7481, orth=62.7314, grad=2369.35, tok/s=650, lr=3.0e-04]  \n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:16,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:12,  2.29s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:04,  2.19s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:04,  2.22s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:00,  2.18s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:59,  2.22s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:55,  2.17s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:54,  2.20s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:50,  2.16s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:50,  2.20s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:46,  2.16s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:45,  2.19s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:41,  2.16s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:40,  2.19s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:32<01:37,  2.16s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:36,  2.20s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:32,  2.16s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:28,  2.16s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:43<01:27,  2.20s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:45<01:24,  2.17s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:23,  2.20s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.16s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:19,  2.20s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:15,  2.16s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:56<01:14,  2.20s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:58<01:11,  2.17s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:10,  2.20s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:07,  2.16s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:05,  2.20s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:07<01:02,  2.16s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:09<01:01,  2.19s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.16s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:57,  2.20s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:53,  2.16s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:18<00:52,  2.19s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:20<00:49,  2.16s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:48,  2.19s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:45,  2.15s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.19s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:40,  2.15s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:31<00:39,  2.20s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:33<00:36,  2.16s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:35,  2.19s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:32,  2.15s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.19s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:42<00:28,  2.17s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:44<00:26,  2.20s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:46<00:23,  2.16s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.19s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.16s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:53<00:17,  2.20s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:55<00:15,  2.16s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:57<00:13,  2.20s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [01:59<00:10,  2.17s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.17s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:06<00:04,  2.20s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:08<00:02,  2.16s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:10<00:00,  2.01s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 50: Eval Loss: 10.7425, PPL: 46279.31\n",
      "🎯 New best eval loss: 10.7425\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 1/5:  50% 99/200 [12:52<10:37,  6.32s/it, total=28.2090, lm=10.3673, orth=17.8417, grad=722.89, tok/s=530, lr=2.9e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:17,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:13,  2.30s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:05,  2.20s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:04,  2.23s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<01:59,  2.18s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:59,  2.22s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:55,  2.18s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:54,  2.21s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:50,  2.17s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:49,  2.20s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:46,  2.18s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:45,  2.21s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:41,  2.17s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:32<01:37,  2.17s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.18s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:32,  2.21s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:28,  2.17s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:43<01:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:24,  2.17s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:23,  2.20s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.16s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:15,  2.17s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:14,  2.20s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:11,  2.17s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:10,  2.20s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:07,  2.17s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:05,  2.20s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:07<01:02,  2.16s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.15s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.19s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:57,  2.21s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:54,  2.17s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:18<00:51,  2.14s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.19s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.16s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.19s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.16s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:41,  2.19s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:40,  2.22s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.19s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.15s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:42<00:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:44<00:26,  2.19s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:22,  2.23s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.19s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:53<00:17,  2.16s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.18s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:11,  2.21s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.17s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.23s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:10<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 100: Eval Loss: 10.3428, PPL: 31032.51\n",
      "🎯 New best eval loss: 10.3428\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 1/5:  74% 149/200 [20:27<05:19,  6.27s/it, total=253.7290, lm=9.6887, orth=244.0403, grad=396472.03, tok/s=501, lr=2.8e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:18,  2.35s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:14,  2.31s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:10,  2.30s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:04,  2.21s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:02,  2.23s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:58,  2.20s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:53,  2.18s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:49,  2.15s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:49,  2.19s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.22s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.18s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.21s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:39,  2.17s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.20s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.17s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:32,  2.15s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.19s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:30,  2.22s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:43<01:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.18s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.21s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.17s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:15,  2.15s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:14,  2.19s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:13,  2.22s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.18s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.22s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:05,  2.18s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.18s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.15s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.19s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:55,  2.21s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:18<00:52,  2.17s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.21s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.17s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.17s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:40,  2.14s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.19s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.22s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.18s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:32,  2.15s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.19s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:42<00:28,  2.16s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:23,  2.17s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.20s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:20,  2.22s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:53<00:17,  2.18s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.16s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.19s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:10,  2.16s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.16s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.20s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.22s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.06s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 150: Eval Loss: 9.5466, PPL: 13996.56\n",
      "🎯 New best eval loss: 9.5466\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 1/5: 100% 199/200 [28:04<00:06,  6.29s/it, total=19.4591, lm=8.9568, orth=10.5023, grad=3085.99, tok/s=486, lr=2.7e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:16,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:06,  2.19s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:06,  2.22s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:02,  2.19s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.22s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:00,  2.24s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:55,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:51,  2.15s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:52,  2.20s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:21<01:48,  2.16s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.20s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:43,  2.16s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.20s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:42,  2.23s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:32<01:38,  2.19s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:34,  2.16s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.19s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:43<01:26,  2.16s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:17,  2.16s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:17,  2.20s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:56<01:13,  2.17s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.21s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.17s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:07,  2.24s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:07<01:03,  2.19s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.16s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.20s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.16s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:55,  2.20s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:18<00:52,  2.17s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.20s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:48,  2.22s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.16s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:31<00:38,  2.16s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.19s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.16s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:33,  2.20s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:31,  2.23s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:42<00:28,  2.18s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:44<00:25,  2.15s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.19s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.16s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.20s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:53<00:17,  2.16s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:55<00:15,  2.20s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.23s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:10,  2.19s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.16s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:06<00:04,  2.16s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:10<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 200: Eval Loss: 8.7827, PPL: 6520.43\n",
      "🎯 New best eval loss: 8.7827\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 1/5: 100% 200/200 [30:26<00:00,  9.13s/it, total=19.4591, lm=8.9568, orth=10.5023, grad=3085.99, tok/s=486, lr=2.7e-04]\n",
      "Epoch 1 Summary - Avg Train Loss: 245.6967, Time: 30.4m\n",
      "Epoch 2/5:  24% 49/200 [05:15<15:51,  6.30s/it, total=11.1137, lm=8.1368, orth=2.9769, grad=267.34, tok/s=477, lr=2.6e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:27,  2.50s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:17,  2.37s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:08,  2.25s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:07,  2.27s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.21s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:00,  2.23s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:55,  2.18s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:55,  2.22s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:51,  2.19s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.22s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:46,  2.18s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.21s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:42,  2.17s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:41,  2.22s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.17s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:32,  2.21s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.18s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:20,  2.22s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.18s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:11,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:10,  2.21s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:07,  2.19s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.22s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.18s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:01,  2.21s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.18s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.18s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.21s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:36,  2.17s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.21s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.18s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.21s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.17s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.20s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:23,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.22s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.18s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.17s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.20s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.18s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.18s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.21s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.17s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 250: Eval Loss: 7.8151, PPL: 2477.73\n",
      "🎯 New best eval loss: 7.8151\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 2/5:  50% 99/200 [12:54<10:36,  6.30s/it, total=9.0929, lm=7.3227, orth=1.7703, grad=234.29, tok/s=471, lr=2.4e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:16,  2.31s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:06,  2.19s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:07,  2.23s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:06,  2.26s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.20s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:00,  2.24s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:55,  2.22s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:51,  2.18s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:21<01:47,  2.15s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.20s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.23s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:42,  2.18s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:41,  2.21s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.18s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.18s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:29,  2.23s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:16,  2.17s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:13,  2.16s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.20s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:07,  2.18s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:04,  2.15s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.17s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.20s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.17s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:54,  2.20s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.23s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.19s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.16s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.16s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.17s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.20s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:35,  2.22s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:32,  2.18s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:25,  2.16s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.20s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.17s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.20s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.24s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.19s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:12,  2.16s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:10,  2.20s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.16s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.17s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.20s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.04s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 300: Eval Loss: 7.0019, PPL: 1098.77\n",
      "🎯 New best eval loss: 7.0019\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 2/5:  74% 149/200 [20:32<05:23,  6.34s/it, total=7.6382, lm=7.2061, orth=0.4321, grad=42.23, tok/s=468, lr=2.2e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:16,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:13,  2.30s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:06,  2.22s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:05,  2.24s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:03,  2.25s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:58,  2.20s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:58,  2.23s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:54,  2.20s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:49,  2.18s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:45,  2.15s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.19s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:40,  2.18s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.17s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.20s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.17s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:28,  2.15s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:27,  2.19s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.18s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.22s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.18s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:13,  2.17s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:10,  2.15s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.19s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:09,  2.23s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:05,  2.18s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:04,  2.21s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.18s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.18s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:53,  2.16s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:52,  2.19s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:51,  2.22s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.18s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.22s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.18s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.21s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.17s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:36,  2.15s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:35,  2.20s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.18s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.21s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.18s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:23,  2.16s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.19s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.16s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.19s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.19s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:10,  2.16s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.19s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.17s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.20s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.18s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.08s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 350: Eval Loss: 6.8442, PPL: 938.39\n",
      "🎯 New best eval loss: 6.8442\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 2/5: 100% 199/200 [28:10<00:06,  6.30s/it, total=7.8490, lm=7.1612, orth=0.6878, grad=38.68, tok/s=465, lr=2.0e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:16,  2.31s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:13,  2.30s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:05,  2.21s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:00,  2.16s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.22s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:57,  2.18s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:57,  2.21s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:56,  2.25s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:52,  2.20s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:48,  2.18s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.18s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.21s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:40,  2.18s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:38,  2.23s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.18s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:29,  2.19s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:43<01:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.20s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.17s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.19s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:19,  2.22s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:54<01:16,  2.19s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:13,  2.16s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.20s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.16s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:05<01:05,  2.17s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:02,  2.23s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.18s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.16s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:16<00:54,  2.20s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:18<00:52,  2.17s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.20s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.16s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:29<00:41,  2.19s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:38,  2.15s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.19s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.16s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:40<00:30,  2.17s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:23,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.15s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:51<00:19,  2.19s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:53<00:17,  2.16s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.19s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:12,  2.16s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:10,  2.19s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:02<00:08,  2.23s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:04<00:06,  2.19s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:06<00:04,  2.15s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:10<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 400: Eval Loss: 6.7890, PPL: 888.00\n",
      "🎯 New best eval loss: 6.7890\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 2/5: 100% 200/200 [30:33<00:00,  9.17s/it, total=7.8490, lm=7.1612, orth=0.6878, grad=38.68, tok/s=465, lr=2.0e-04]\n",
      "Epoch 2 Summary - Avg Train Loss: 10.2374, Time: 61.1m\n",
      "Epoch 3/5:  24% 49/200 [05:16<15:56,  6.34s/it, total=9.5208, lm=7.1243, orth=2.3965, grad=316.23, tok/s=462, lr=1.7e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:28,  2.52s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:11,  2.27s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:04,  2.19s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:05,  2.24s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:04,  2.26s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:58,  2.23s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:53,  2.19s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:54,  2.25s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:50,  2.21s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:46,  2.18s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:45,  2.21s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:44,  2.23s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:40,  2.23s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:36,  2.19s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:32,  2.16s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:32,  2.20s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:29,  2.18s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:27,  2.23s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:23,  2.19s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:19,  2.16s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:19,  2.20s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.19s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.23s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.20s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:11,  2.24s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:10,  2.27s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:07,  2.24s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:02,  2.24s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:13<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:58,  2.25s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:55,  2.22s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.24s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:22<00:51,  2.25s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:24<00:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:45,  2.17s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:33<00:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:35<00:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.21s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:33,  2.25s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.18s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:46<00:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:23,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.22s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.18s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:55<00:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:57<00:15,  2.23s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.19s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.17s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.17s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:08<00:04,  2.20s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.17s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:12<00:00,  2.08s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 450: Eval Loss: 6.7822, PPL: 882.04\n",
      "🎯 New best eval loss: 6.7822\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 3/5:  50% 99/200 [12:54<10:36,  6.30s/it, total=7.4905, lm=7.0635, orth=0.4270, grad=77.98, tok/s=461, lr=1.5e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:17,  2.33s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:13,  2.31s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:05,  2.21s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:08<02:05,  2.23s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:00,  2.18s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:00,  2.22s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:56,  2.23s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:52,  2.20s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.24s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:47,  2.25s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.21s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:42,  2.24s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.19s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:38,  2.23s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.19s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.18s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.21s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:24,  2.18s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.17s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:14,  2.21s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:11,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:10,  2.21s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:07,  2.17s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.21s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:02,  2.17s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:02,  2.22s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.18s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.21s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.17s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:52,  2.21s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.21s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.17s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:35,  2.21s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.18s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.21s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.18s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:23,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.21s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.17s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.18s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.22s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.18s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.18s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.18s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 500: Eval Loss: 6.7544, PPL: 857.81\n",
      "🎯 New best eval loss: 6.7544\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 3/5:  74% 149/200 [20:35<05:22,  6.33s/it, total=7.3143, lm=7.1872, orth=0.1271, grad=9.49, tok/s=459, lr=1.3e-04] \n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:29,  2.54s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:12,  2.29s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:10,  2.28s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:03,  2.21s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:02,  2.24s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:58,  2.19s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:58,  2.23s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:53,  2.18s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:49,  2.18s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.22s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.18s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:40,  2.18s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.17s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:35,  2.21s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.18s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:30,  2.21s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.20s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.17s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.21s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.17s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:13,  2.17s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.21s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.18s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:05,  2.18s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.17s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.17s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:55,  2.20s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:52,  2.17s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.20s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.18s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.21s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.17s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.21s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.17s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.17s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:33,  2.21s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.17s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.18s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.18s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.21s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.18s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.18s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.21s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.17s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.21s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.05s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 550: Eval Loss: 6.7526, PPL: 856.25\n",
      "🎯 New best eval loss: 6.7526\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 3/5: 100% 199/200 [28:14<00:06,  6.35s/it, total=7.2963, lm=7.1527, orth=0.1436, grad=12.32, tok/s=458, lr=1.0e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:28,  2.52s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:11,  2.27s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:09,  2.28s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:03,  2.21s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:03,  2.25s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:58,  2.20s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:58,  2.23s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:53,  2.18s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:52,  2.21s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:49,  2.18s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.18s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.21s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:39,  2.17s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.18s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.21s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.17s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:27,  2.18s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.18s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.21s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.17s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:14,  2.18s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.21s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.17s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:05,  2.17s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:04,  2.21s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.17s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.17s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:55,  2.21s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:52,  2.18s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.21s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.18s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.21s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.17s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:42,  2.22s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.18s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.17s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:38<00:33,  2.20s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.18s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.21s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.18s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:20,  2.22s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.19s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.21s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.18s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:11,  2.21s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.18s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.23s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.18s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.21s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.05s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 600: Eval Loss: 6.7237, PPL: 831.85\n",
      "🎯 New best eval loss: 6.7237\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 3/5: 100% 200/200 [30:37<00:00,  9.19s/it, total=7.2963, lm=7.1527, orth=0.1436, grad=12.32, tok/s=458, lr=1.0e-04]\n",
      "Epoch 3 Summary - Avg Train Loss: 7.9776, Time: 91.8m\n",
      "Epoch 4/5:  24% 49/200 [05:16<15:58,  6.35s/it, total=7.2208, lm=7.0438, orth=0.1770, grad=7.85, tok/s=457, lr=8.3e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:27,  2.51s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:11,  2.26s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:09,  2.28s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:04,  2.22s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:03,  2.24s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:58,  2.19s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:53,  2.18s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:48,  2.18s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:44,  2.18s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.21s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:40,  2.18s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:39,  2.22s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.18s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.21s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.17s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:30,  2.21s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:27,  2.18s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.18s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.21s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.18s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.22s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:14,  2.18s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.21s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:09,  2.18s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:05,  2.19s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:01,  2.18s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.17s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:55,  2.21s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:52,  2.18s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.21s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.17s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.21s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.18s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:42,  2.22s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.18s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:34,  2.18s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:33,  2.21s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.18s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.21s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.18s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:21,  2.19s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:20,  2.23s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.19s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:13,  2.19s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.19s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.22s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.18s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.21s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.05s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 650: Eval Loss: 6.6773, PPL: 794.13\n",
      "🎯 New best eval loss: 6.6773\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 4/5:  50% 99/200 [12:55<10:36,  6.30s/it, total=7.0485, lm=7.0350, orth=0.0135, grad=5.96, tok/s=456, lr=6.3e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:17,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:14,  2.32s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:06,  2.22s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:05,  2.24s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:00,  2.19s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:59,  2.22s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:55,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:55,  2.22s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:51,  2.19s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.22s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.19s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:47,  2.23s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.20s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:42,  2.23s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.20s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:38,  2.24s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.21s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:34,  2.24s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:29,  2.23s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.20s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.23s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.20s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:20,  2.22s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.18s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:02<01:10,  2.21s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:07,  2.18s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.21s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:02,  2.17s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:01,  2.20s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.19s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.21s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.18s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.21s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:48,  2.22s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.21s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.22s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.18s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.21s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.17s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:24,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.22s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.18s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.18s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.23s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.18s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.18s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 700: Eval Loss: 6.5491, PPL: 698.60\n",
      "🎯 New best eval loss: 6.5491\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 4/5:  74% 149/200 [20:37<05:22,  6.32s/it, total=7.1165, lm=7.0222, orth=0.0943, grad=13.01, tok/s=455, lr=4.5e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:17,  2.32s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:15,  2.33s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:07,  2.23s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:06,  2.27s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.21s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:00,  2.23s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:55,  2.23s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:51,  2.19s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.23s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.19s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.22s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:42,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:42,  2.23s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.19s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.22s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.19s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.19s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.19s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:20,  2.23s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.19s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.23s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.19s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:02<01:10,  2.22s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:07,  2.19s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.22s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.19s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:02,  2.22s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.18s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.20s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.23s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.19s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:24<00:48,  2.22s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:45,  2.19s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.23s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:40,  2.24s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:35<00:37,  2.21s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:36,  2.25s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:31,  2.26s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:44<00:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:46<00:27,  2.25s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.27s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:53<00:20,  2.23s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:55<00:17,  2.25s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:57<00:15,  2.21s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.23s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:11,  2.21s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:04<00:08,  2.24s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:06<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:08<00:04,  2.23s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:12<00:00,  2.04s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 750: Eval Loss: 6.4706, PPL: 645.90\n",
      "🎯 New best eval loss: 6.4706\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 4/5: 100% 199/200 [28:17<00:06,  6.32s/it, total=6.9023, lm=6.8984, orth=0.0038, grad=3.12, tok/s=454, lr=3.0e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:28,  2.52s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:18,  2.40s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:08,  2.26s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:07,  2.28s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.22s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:01,  2.25s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.20s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:18<01:56,  2.24s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:52,  2.20s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.23s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.19s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.23s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:29<01:42,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:41,  2.22s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.18s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:34,  2.16s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.21s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:40<01:33,  2.23s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.19s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.18s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.23s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:51<01:21,  2.19s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:17,  2.16s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.20s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.23s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.20s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:02<01:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:07,  2.19s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.22s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.18s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.17s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:13<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:58,  2.24s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.19s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.19s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:24<00:49,  2.23s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:43,  2.17s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:40,  2.23s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:35<00:37,  2.20s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.23s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:31,  2.22s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.19s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:46<00:26,  2.17s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.24s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.19s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:55<00:17,  2.22s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:57<00:15,  2.20s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.23s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.19s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.16s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:08<00:04,  2.24s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.20s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:12<00:00,  2.04s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 800: Eval Loss: 6.4115, PPL: 608.82\n",
      "🎯 New best eval loss: 6.4115\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 4/5: 100% 200/200 [30:37<00:00,  9.19s/it, total=6.9023, lm=6.8984, orth=0.0038, grad=3.12, tok/s=454, lr=3.0e-05]\n",
      "Epoch 4 Summary - Avg Train Loss: 7.1254, Time: 122.5m\n",
      "Epoch 5/5:  24% 49/200 [05:16<15:51,  6.30s/it, total=6.8894, lm=6.8884, orth=0.0010, grad=2.94, tok/s=454, lr=1.7e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:19,  2.37s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:15,  2.34s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:08,  2.26s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:07,  2.28s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:02,  2.23s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:02,  2.26s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.21s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:18<01:56,  2.24s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:52,  2.20s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:51,  2.23s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.18s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.21s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:42,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:42,  2.23s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.19s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.22s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.18s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:40<01:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.19s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:20,  2.23s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.19s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:02<01:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:08,  2.21s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.23s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.19s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:02,  2.22s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:13<00:59,  2.19s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.23s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.19s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:24<00:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.22s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.22s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:35<00:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.22s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:31,  2.22s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.18s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:46<00:26,  2.21s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:23,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.22s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.18s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.21s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:57<00:15,  2.18s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.21s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.19s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.22s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.18s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:08<00:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.18s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.04s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 850: Eval Loss: 6.3687, PPL: 583.28\n",
      "🎯 New best eval loss: 6.3687\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 5/5:  50% 99/200 [12:56<10:38,  6.32s/it, total=6.9607, lm=6.9584, orth=0.0023, grad=1.17, tok/s=453, lr=8.3e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:17,  2.34s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:15,  2.33s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:06,  2.22s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:05,  2.25s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:00,  2.19s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<01:59,  2.22s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.19s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:17<01:55,  2.22s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:19<01:51,  2.19s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:50,  2.22s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:46,  2.18s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.22s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:42,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:41,  2.22s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.18s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.22s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.19s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:41<01:29,  2.18s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.18s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:19,  2.22s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.18s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.21s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:11,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:11,  2.22s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:07,  2.18s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.21s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.18s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:01,  2.21s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:58,  2.18s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.18s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.21s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:49,  2.23s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.23s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:39,  2.22s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.19s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.22s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:31,  2.22s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.18s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.19s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.22s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.18s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.22s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.19s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.22s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.19s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.22s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.18s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.22s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.19s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.03s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 900: Eval Loss: 6.3441, PPL: 569.11\n",
      "🎯 New best eval loss: 6.3441\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 5/5:  74% 149/200 [20:35<05:23,  6.34s/it, total=6.8705, lm=6.8672, orth=0.0033, grad=2.04, tok/s=453, lr=2.8e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:28,  2.51s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:18,  2.39s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:09,  2.27s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:07,  2.29s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:02,  2.23s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:02,  2.26s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:18<01:57,  2.26s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:52,  2.21s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:52,  2.26s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:27<01:47,  2.23s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:29<01:42,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:31<01:41,  2.22s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.19s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:37,  2.22s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:33,  2.18s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:40<01:33,  2.22s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:29,  2.18s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:28,  2.22s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:49<01:24,  2.22s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:51<01:20,  2.18s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:53<01:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:16,  2.19s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:15,  2.22s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:11,  2.18s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:02<01:10,  2.21s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:04<01:07,  2.18s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:06,  2.22s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:11<01:02,  2.23s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:13<00:59,  2.19s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:15<00:57,  2.22s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:54,  2.18s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.22s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.18s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:24<00:48,  2.21s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:26<00:45,  2.18s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:28<00:44,  2.21s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.18s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:33<00:39,  2.22s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:35<00:37,  2.18s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:37<00:35,  2.21s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.18s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:31,  2.22s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.19s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:46<00:26,  2.22s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:48<00:24,  2.18s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:50<00:22,  2.21s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.19s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:55<00:17,  2.22s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:57<00:15,  2.18s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:59<00:13,  2.22s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:01<00:10,  2.18s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.22s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.19s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:08<00:04,  2.21s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:10<00:02,  2.18s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.02s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 950: Eval Loss: 6.3310, PPL: 561.74\n",
      "🎯 New best eval loss: 6.3310\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 5/5: 100% 199/200 [28:14<00:06,  6.30s/it, total=6.9347, lm=6.8969, orth=0.0378, grad=3.46, tok/s=452, lr=1.0e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:02<02:27,  2.51s/it]\u001b[A\n",
      "Evaluating:   3% 2/60 [00:04<02:12,  2.28s/it]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:06<02:10,  2.29s/it]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:09<02:08,  2.29s/it]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:11<02:01,  2.22s/it]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:13<02:01,  2.24s/it]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:15<01:56,  2.20s/it]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:18<01:56,  2.24s/it]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:20<01:51,  2.19s/it]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:22<01:48,  2.16s/it]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:24<01:47,  2.20s/it]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:26<01:46,  2.23s/it]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:28<01:43,  2.19s/it]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:30<01:39,  2.16s/it]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:33<01:38,  2.20s/it]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:35<01:35,  2.16s/it]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:37<01:34,  2.20s/it]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:39<01:31,  2.17s/it]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:42<01:30,  2.20s/it]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:44<01:29,  2.23s/it]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:46<01:25,  2.19s/it]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:48<01:22,  2.16s/it]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:50<01:21,  2.21s/it]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:52<01:18,  2.17s/it]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:55<01:17,  2.20s/it]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:57<01:13,  2.17s/it]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:59<01:12,  2.20s/it]\u001b[A\n",
      "Evaluating:  47% 28/60 [01:01<01:11,  2.24s/it]\u001b[A\n",
      "Evaluating:  48% 29/60 [01:03<01:08,  2.20s/it]\u001b[A\n",
      "Evaluating:  50% 30/60 [01:06<01:05,  2.17s/it]\u001b[A\n",
      "Evaluating:  52% 31/60 [01:08<01:03,  2.20s/it]\u001b[A\n",
      "Evaluating:  53% 32/60 [01:10<01:00,  2.17s/it]\u001b[A\n",
      "Evaluating:  55% 33/60 [01:12<00:59,  2.21s/it]\u001b[A\n",
      "Evaluating:  57% 34/60 [01:14<00:56,  2.18s/it]\u001b[A\n",
      "Evaluating:  58% 35/60 [01:17<00:55,  2.21s/it]\u001b[A\n",
      "Evaluating:  60% 36/60 [01:19<00:53,  2.23s/it]\u001b[A\n",
      "Evaluating:  62% 37/60 [01:21<00:50,  2.19s/it]\u001b[A\n",
      "Evaluating:  63% 38/60 [01:23<00:47,  2.16s/it]\u001b[A\n",
      "Evaluating:  65% 39/60 [01:25<00:46,  2.20s/it]\u001b[A\n",
      "Evaluating:  67% 40/60 [01:27<00:43,  2.17s/it]\u001b[A\n",
      "Evaluating:  68% 41/60 [01:30<00:41,  2.20s/it]\u001b[A\n",
      "Evaluating:  70% 42/60 [01:32<00:38,  2.17s/it]\u001b[A\n",
      "Evaluating:  72% 43/60 [01:34<00:37,  2.20s/it]\u001b[A\n",
      "Evaluating:  73% 44/60 [01:36<00:35,  2.24s/it]\u001b[A\n",
      "Evaluating:  75% 45/60 [01:39<00:32,  2.19s/it]\u001b[A\n",
      "Evaluating:  77% 46/60 [01:41<00:30,  2.16s/it]\u001b[A\n",
      "Evaluating:  78% 47/60 [01:43<00:28,  2.20s/it]\u001b[A\n",
      "Evaluating:  80% 48/60 [01:45<00:25,  2.17s/it]\u001b[A\n",
      "Evaluating:  82% 49/60 [01:47<00:24,  2.21s/it]\u001b[A\n",
      "Evaluating:  83% 50/60 [01:49<00:21,  2.18s/it]\u001b[A\n",
      "Evaluating:  85% 51/60 [01:52<00:19,  2.21s/it]\u001b[A\n",
      "Evaluating:  87% 52/60 [01:54<00:17,  2.23s/it]\u001b[A\n",
      "Evaluating:  88% 53/60 [01:56<00:15,  2.19s/it]\u001b[A\n",
      "Evaluating:  90% 54/60 [01:58<00:12,  2.16s/it]\u001b[A\n",
      "Evaluating:  92% 55/60 [02:00<00:11,  2.20s/it]\u001b[A\n",
      "Evaluating:  93% 56/60 [02:03<00:08,  2.17s/it]\u001b[A\n",
      "Evaluating:  95% 57/60 [02:05<00:06,  2.20s/it]\u001b[A\n",
      "Evaluating:  97% 58/60 [02:07<00:04,  2.17s/it]\u001b[A\n",
      "Evaluating:  98% 59/60 [02:09<00:02,  2.21s/it]\u001b[A\n",
      "Evaluating: 100% 60/60 [02:11<00:00,  2.06s/it]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1000: Eval Loss: 6.3270, PPL: 559.47\n",
      "🎯 New best eval loss: 6.3270\n",
      "✅ Saved new best model to checkpoints/orthogonal_a100_large/best_model.pth.tar\n",
      "Epoch 5/5: 100% 200/200 [30:37<00:00,  9.19s/it, total=6.9347, lm=6.8969, orth=0.0378, grad=3.46, tok/s=452, lr=1.0e-06]\n",
      "Epoch 5 Summary - Avg Train Loss: 6.8692, Time: 153.3m\n",
      "\n",
      "✅ HGNN-MoE Training Complete!\n",
      "🎯 Best eval loss during this run: 6.3270\n",
      "⏱️ Total time for this run: 153.4 minutes\n",
      "📊 Training results plot saved to plots/orthogonal_a100_large_training_results.png\n",
      "🔄 Loading best model from checkpoints/orthogonal_a100_large/best_model.pth.tar for final analysis...\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "Using HGNNExpertCoupler for MoE layer with all_triplets strategy.\n",
      "🔄 Loading checkpoint from 'checkpoints/orthogonal_a100_large/best_model.pth.tar'\n",
      "✅ Checkpoint loaded. Resuming from epoch 5, step 1000, best_eval_loss 6.3270\n",
      "\n",
      "🧠 Expert Communication Analysis\n",
      "\n",
      "LAYER_0:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: 0.378, Max: 2.690\n",
      "\n",
      "LAYER_1:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: 0.279, Max: 1.994\n",
      "\n",
      "LAYER_2:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: -0.206, Max: 1.105\n",
      "\n",
      "LAYER_3:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: -0.064, Max: 1.753\n",
      "\n",
      "LAYER_4:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: 0.150, Max: 1.644\n",
      "\n",
      "LAYER_5:\n",
      "  HGNN Layer 1 - Hyperedge Weights:\n",
      "    Avg connectivity: -0.082, Max: 2.214\n",
      "🎨 Expert connectivity plot saved to plots/orthogonal_a100_large_expert_connectivity.png\n",
      "\n",
      "⚡ HGNN-MoE Efficiency Analysis\n",
      "  Total Parameters: 169,799,881\n",
      "  Expert Parameters: 113,485,824 (66.8%)\n",
      "  HGNN Coord Params: 4,734,072 (2.8%)\n",
      "  Other (Embeds, etc.): 51,579,985 (30.4%)\n",
      "  Expert Utilization: ALL 6 experts active per layer.\n",
      "  HGNN Coordination: 2 HGNN layers per expert group.\n",
      "\n",
      "🎉 GNN-MoE Hyperparameter Script Execution Finished Successfully!\n",
      "   Run Name: orthogonal_a100_large\n",
      "   Data Mode: REAL_WIKITEXT_2_V1\n",
      "   Best Eval Loss from run: 6.3270\n",
      "   Best Eval Perplexity from run: 559.47\n",
      "==============================================\n",
      "📝 Run summary saved to checkpoints/orthogonal_a100_large/run_summary.json\n"
     ]
    }
   ],
   "source": [
    "!python run_gnn_moe.py \\\n",
    "  --dataset_config_name wikitext-2-v1 \\\n",
    "  --coupler_type HGNN \\\n",
    "  --static_hyperedge_strategy all_triplets \\\n",
    "  --num_experts 6 \\\n",
    "  --embed_dim 512 \\\n",
    "  --num_layers 6 \\\n",
    "  --batch_size 32 \\\n",
    "  --epochs 5 \\\n",
    "  --max_batches_per_epoch 200 \\\n",
    "  --eval_every 50 \\\n",
    "  --run_name orthogonal_a100_large \\\n",
    "  --apply_orthogonality_loss \\\n",
    "  --orthogonality_loss_weight 0.15 \\\n",
    "  --orthogonality_warmup_steps 100 \\\n",
    "  --learning_rate 3e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1zGUwoA1TFK",
    "outputId": "380be014-c8bb-4a03-c611-6cf4f58f0771",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Adjusting num_heads from 8 to 4 based on embed_dim 256\n",
      "Adjusting num_heads from 8 to 4 based on embed_dim 256\n",
      "Overriding config.apply_weight_orthogonality_loss from False to CLI arg: True\n",
      "📁 Created checkpoint directory: checkpoints\n",
      "===== GNN-MoE Hyperparameter Script Execution Started =====\n",
      "Effective Config: GNNMoEConfig(vocab_size=50257, max_seq_length=128, embed_dim=256, num_layers=4, num_heads=4, dropout_rate=0.1, num_experts=4, gnn_layers=2, batch_size=32, learning_rate=0.0005, epochs=8, max_batches_per_epoch=-1, eval_every=200, dataset_name='wikitext', dataset_config_name='wikitext-2-v1', num_train_samples=-1, num_eval_samples=-1, checkpoint_dir='checkpoints', resume_checkpoint=None, run_name=None, seed=42, num_workers_dataloader=2, coupler_type='GNN', hgnn_conv_type='HypergraphConv', static_hyperedge_strategy='all_pairs', hgnn_learnable_edge_weights=True, apply_orthogonality_loss=True, orthogonality_loss_weight=0.1, orthogonality_aggregation='mean', orthogonality_loss_type='gram_identity', orthogonality_warmup_steps=1000, track_expert_specialization=True, apply_weight_orthogonality_loss=True, weight_orthogonality_loss_weight=0.05, weight_orthogonality_target_layer='ffn_input', weight_orthogonality_normalization='frobenius', combine_weight_output_orthogonality=False)\n",
      "🚀 Device: CUDA (Available: 1)\n",
      "📁 Created 'plots' directory for output visualizations.\n",
      "✅ Environment ready. Seed: 42, Device: cuda\n",
      "🚀 Setting up data loading for wikitext / wikitext-2-v1...\n",
      "Downloading tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 168kB/s]\n",
      "Downloading config.json: 100% 665/665 [00:00<00:00, 4.66MB/s]\n",
      "Downloading vocab.json: 100% 1.04M/1.04M [00:00<00:00, 14.9MB/s]\n",
      "Downloading merges.txt: 100% 456k/456k [00:00<00:00, 9.14MB/s]\n",
      "Downloading tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 24.5MB/s]\n",
      "📦 Attempting wikitext (wikitext-2-v1) dataset loading...\n",
      "Downloading readme: 100% 10.5k/10.5k [00:00<00:00, 32.9MB/s]\n",
      "Downloading data files:   0% 0/3 [00:00<?, ?it/s]\n",
      "Downloading data:   0% 0.00/685k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 685k/685k [00:00<00:00, 2.87MB/s]\n",
      "Downloading data files:  33% 1/3 [00:00<00:00,  4.15it/s]\n",
      "Downloading data:   0% 0.00/6.07M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 6.07M/6.07M [00:00<00:00, 30.8MB/s]\n",
      "Downloading data files:  67% 2/3 [00:00<00:00,  4.62it/s]\n",
      "Downloading data:   0% 0.00/618k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100% 618k/618k [00:00<00:00, 5.23MB/s]\n",
      "Downloading data files: 100% 3/3 [00:00<00:00,  5.35it/s]\n",
      "Extracting data files: 100% 3/3 [00:00<00:00, 2063.79it/s]\n",
      "Generating test split: 100% 4358/4358 [00:00<00:00, 92700.97 examples/s]\n",
      "Generating train split: 100% 36718/36718 [00:00<00:00, 701802.99 examples/s]\n",
      "Generating validation split: 100% 3760/3760 [00:00<00:00, 638071.82 examples/s]\n",
      "Raw lines >30 chars: Train 18131, Eval 1913\n",
      "✅ SUCCESS: Real wikitext-2-v1 data loaded!\n",
      "\n",
      "✅ DATA LOADING COMPLETE!\n",
      "🎯 Mode: REAL_WIKITEXT_2_V1\n",
      "📊 Train samples: 18131, Eval samples: 1913\n",
      "📦 Train batches: 567, Eval batches: 60\n",
      "🔤 Vocabulary: 50,257 tokens (using gpt2)\n",
      "\n",
      "🏗️ Creating GNN-MoE Model with effective vocab_size: 50257\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "\n",
      "🚀 Starting/Resuming GNN-MoE Training on cuda\n",
      "📊 Model: 39,773,401 parameters\n",
      "🎯 Training: 8 epochs × 567 batches/epoch = 4536 total steps\n",
      "💾 Checkpoints will be saved in: checkpoints\n",
      "Epoch 1/8:  35% 199/567 [00:32<00:56,  6.54it/s, total=6.3367, lm=6.2293, orth=0.1074, grad=3.99, tok/s=25595, lr=5.0e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:10,  5.46it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:04, 13.92it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:03, 17.55it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 19.53it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.60it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.20it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.57it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.84it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.96it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.07it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.23it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.42it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.45it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.53it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.55it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.58it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.54it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.54it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.62it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.74it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 200: Eval Loss: 5.6530, PPL: 285.14\n",
      "🎯 New best eval loss: 5.6530\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 1/8:  70% 399/567 [01:06<00:25,  6.47it/s, total=5.8685, lm=5.8454, orth=0.0232, grad=1.81, tok/s=24535, lr=4.9e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.21it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.91it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.66it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 19.26it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.33it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.14it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.61it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.91it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.13it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.34it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.22it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.30it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 21.98it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.23it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.40it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.33it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.51it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.59it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.56it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.69it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 400: Eval Loss: 5.3363, PPL: 207.74\n",
      "🎯 New best eval loss: 5.3363\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 1/8: 100% 567/567 [01:37<00:00,  5.81it/s, total=5.6311, lm=5.6018, orth=0.0293, grad=2.08, tok/s=23818, lr=4.8e-04]\n",
      "Epoch 1 Summary - Avg Train Loss: 7.4620, Time: 1.6m\n",
      "Epoch 2/8:   6% 32/567 [00:05<01:20,  6.62it/s, total=5.5083, lm=5.4989, orth=0.0094, grad=1.08, tok/s=23729, lr=4.8e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.12it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.03it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.04it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.45it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.20it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.81it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 22.09it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.36it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.54it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.50it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.62it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.77it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.84it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.59it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.51it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.66it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.66it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.71it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.71it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.79it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 600: Eval Loss: 5.1480, PPL: 172.09\n",
      "🎯 New best eval loss: 5.1480\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 2/8:  41% 232/567 [00:40<00:51,  6.55it/s, total=5.2429, lm=5.2101, orth=0.0328, grad=2.21, tok/s=23639, lr=4.6e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.07it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.52it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.28it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 18.91it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 19.82it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 20.33it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 20.75it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.01it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.20it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 21.24it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.54it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.58it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 21.60it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 21.87it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.12it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.27it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.37it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.30it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.12it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.34it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 800: Eval Loss: 5.0321, PPL: 153.25\n",
      "🎯 New best eval loss: 5.0321\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 2/8:  76% 432/567 [01:15<00:20,  6.65it/s, total=5.2205, lm=5.2169, orth=0.0036, grad=0.85, tok/s=23607, lr=4.4e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.21it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.09it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.86it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.30it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.08it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.60it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.92it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.20it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.42it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.55it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.52it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.48it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.63it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.70it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.73it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.73it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.78it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.82it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.80it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.86it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1000: Eval Loss: 4.9106, PPL: 135.72\n",
      "🎯 New best eval loss: 4.9106\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 2/8: 100% 567/567 [01:40<00:00,  5.66it/s, total=4.9177, lm=4.8978, orth=0.0199, grad=1.91, tok/s=23394, lr=4.3e-04]\n",
      "Epoch 2 Summary - Avg Train Loss: 5.2983, Time: 3.3m\n",
      "Epoch 3/8:  11% 65/567 [00:10<01:16,  6.60it/s, total=4.9228, lm=4.9203, orth=0.0025, grad=0.96, tok/s=23457, lr=4.2e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.22it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.19it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.30it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.65it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.48it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.90it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 22.27it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.50it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.64it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.63it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.70it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.64it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.55it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.43it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.51it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.63it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.65it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.67it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.74it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.82it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1200: Eval Loss: 4.8390, PPL: 126.34\n",
      "🎯 New best eval loss: 4.8390\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 3/8:  47% 265/567 [00:45<00:45,  6.57it/s, total=4.8846, lm=4.8788, orth=0.0058, grad=1.11, tok/s=23450, lr=3.9e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.05it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.82it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.52it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.12it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.14it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.71it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 22.10it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.40it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.54it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.58it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.15it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.23it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.47it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.69it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.84it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.97it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 23.01it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.89it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.29it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.57it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1400: Eval Loss: 4.7760, PPL: 118.63\n",
      "🎯 New best eval loss: 4.7760\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 3/8:  82% 465/567 [01:20<00:15,  6.68it/s, total=4.7995, lm=4.7288, orth=0.0707, grad=2.75, tok/s=23452, lr=3.6e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.18it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.10it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.18it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.38it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.06it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.51it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.85it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.08it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.29it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.20it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.35it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.53it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.61it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.66it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.73it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.71it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.70it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.65it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.62it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.47it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1600: Eval Loss: 4.7097, PPL: 111.02\n",
      "🎯 New best eval loss: 4.7097\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 3/8: 100% 567/567 [01:39<00:00,  5.67it/s, total=4.8293, lm=4.8115, orth=0.0177, grad=1.64, tok/s=23275, lr=3.5e-04]\n",
      "Epoch 3 Summary - Avg Train Loss: 4.8285, Time: 5.0m\n",
      "Epoch 4/8:  17% 98/567 [00:15<01:10,  6.63it/s, total=4.5856, lm=4.5847, orth=0.0009, grad=1.06, tok/s=23378, lr=3.3e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.18it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.06it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.12it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.49it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.38it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.73it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.88it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.09it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.20it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.32it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.45it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.42it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.48it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.11it/s]\u001b[A\n",
      "Evaluating:  70% 42/60 [00:01<00:00, 21.57it/s]\u001b[A\n",
      "Evaluating:  73% 44/60 [00:02<00:00, 21.16it/s]\u001b[A\n",
      "Evaluating:  78% 47/60 [00:02<00:00, 21.05it/s]\u001b[A\n",
      "Evaluating:  83% 50/60 [00:02<00:00, 20.45it/s]\u001b[A\n",
      "Evaluating:  88% 53/60 [00:02<00:00, 20.62it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 20.47it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 20.86it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 1800: Eval Loss: 4.6780, PPL: 107.55\n",
      "🎯 New best eval loss: 4.6780\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 4/8:  53% 298/567 [00:50<00:40,  6.64it/s, total=4.3924, lm=4.3895, orth=0.0030, grad=1.14, tok/s=23390, lr=3.0e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  6.91it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.76it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.87it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.27it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.03it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.55it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.58it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.64it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.92it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.02it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.98it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.96it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 21.94it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.16it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 21.31it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 21.15it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 21.58it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 21.91it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 21.96it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 21.18it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 2000: Eval Loss: 4.6350, PPL: 103.03\n",
      "🎯 New best eval loss: 4.6350\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 4/8:  88% 498/567 [01:25<00:10,  6.59it/s, total=4.5730, lm=4.5567, orth=0.0163, grad=1.54, tok/s=23390, lr=2.6e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.05it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.60it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.55it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.06it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.25it/s]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:00<00:02, 20.17it/s]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:00<00:02, 20.63it/s]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:01<00:01, 20.85it/s]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:01<00:01, 21.04it/s]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:01<00:01, 21.33it/s]\u001b[A\n",
      "Evaluating:  50% 30/60 [00:01<00:01, 21.52it/s]\u001b[A\n",
      "Evaluating:  55% 33/60 [00:01<00:01, 21.66it/s]\u001b[A\n",
      "Evaluating:  60% 36/60 [00:01<00:01, 21.76it/s]\u001b[A\n",
      "Evaluating:  65% 39/60 [00:01<00:00, 21.79it/s]\u001b[A\n",
      "Evaluating:  70% 42/60 [00:02<00:00, 21.77it/s]\u001b[A\n",
      "Evaluating:  75% 45/60 [00:02<00:00, 21.70it/s]\u001b[A\n",
      "Evaluating:  80% 48/60 [00:02<00:00, 21.74it/s]\u001b[A\n",
      "Evaluating:  85% 51/60 [00:02<00:00, 21.89it/s]\u001b[A\n",
      "Evaluating:  90% 54/60 [00:02<00:00, 21.94it/s]\u001b[A\n",
      "Evaluating:  95% 57/60 [00:02<00:00, 22.06it/s]\u001b[A\n",
      "Evaluating: 100% 60/60 [00:02<00:00, 22.14it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 2200: Eval Loss: 4.5920, PPL: 98.69\n",
      "🎯 New best eval loss: 4.5920\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 4/8: 100% 567/567 [01:39<00:00,  5.67it/s, total=4.3716, lm=4.3650, orth=0.0067, grad=1.51, tok/s=23215, lr=2.5e-04]\n",
      "Epoch 4 Summary - Avg Train Loss: 4.4647, Time: 6.7m\n",
      "Epoch 5/8:  23% 131/567 [00:20<01:07,  6.43it/s, total=4.0384, lm=4.0322, orth=0.0062, grad=1.29, tok/s=23334, lr=2.3e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.14it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.84it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.72it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 19.99it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.76it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 20.84it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.04it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.09it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.49it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 21.72it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.64it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.69it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 21.86it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.00it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.15it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.12it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.21it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.23it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.18it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.02it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 2400: Eval Loss: 4.5876, PPL: 98.26\n",
      "🎯 New best eval loss: 4.5876\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 5/8:  58% 331/567 [00:55<00:36,  6.46it/s, total=4.0710, lm=4.0678, orth=0.0032, grad=1.25, tok/s=23331, lr=1.9e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  6.93it/s]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:00<00:04, 13.33it/s]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:00<00:03, 16.44it/s]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:00<00:03, 17.21it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 17.65it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 18.85it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 20.02it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:01<00:02, 20.23it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 20.86it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.21it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 21.46it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.62it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.67it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 21.39it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:02<00:00, 21.64it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 21.84it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 21.96it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.01it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.07it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.03it/s]\u001b[A\n",
      "Evaluating:  95% 57/60 [00:02<00:00, 21.05it/s]\u001b[A\n",
      "Evaluating:  98% 59/60 [00:02<00:00, 20.38it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 2600: Eval Loss: 4.5703, PPL: 96.57\n",
      "🎯 New best eval loss: 4.5703\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 5/8:  94% 531/567 [01:31<00:05,  6.63it/s, total=4.2122, lm=4.2103, orth=0.0019, grad=1.22, tok/s=23271, lr=1.6e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  6.90it/s]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:00<00:04, 13.17it/s]\u001b[A\n",
      "Evaluating:   8% 5/60 [00:00<00:03, 15.96it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:03, 17.25it/s]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:00<00:02, 18.02it/s]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:00<00:02, 18.51it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 18.83it/s]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:00<00:02, 19.02it/s]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:00<00:02, 19.32it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:01<00:02, 19.40it/s]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:01<00:02, 19.45it/s]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:01<00:01, 18.90it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 19.02it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 20.19it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.02it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.63it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.07it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:02<00:00, 22.27it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.44it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.58it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.70it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.74it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.74it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.80it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 2800: Eval Loss: 4.5433, PPL: 94.00\n",
      "🎯 New best eval loss: 4.5433\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 5/8: 100% 567/567 [01:42<00:00,  5.55it/s, total=3.9819, lm=3.9334, orth=0.0485, grad=3.35, tok/s=23083, lr=1.6e-04]\n",
      "Epoch 5 Summary - Avg Train Loss: 4.1793, Time: 8.4m\n",
      "Epoch 6/8:  29% 164/567 [00:25<01:01,  6.60it/s, total=3.8008, lm=3.7942, orth=0.0067, grad=1.34, tok/s=23215, lr=1.3e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.17it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.87it/s]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:00<00:03, 17.03it/s]\u001b[A\n",
      "Evaluating:  15% 9/60 [00:00<00:02, 19.37it/s]\u001b[A\n",
      "Evaluating:  20% 12/60 [00:00<00:02, 20.59it/s]\u001b[A\n",
      "Evaluating:  25% 15/60 [00:00<00:02, 20.51it/s]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:00<00:02, 20.94it/s]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:01<00:01, 21.39it/s]\u001b[A\n",
      "Evaluating:  40% 24/60 [00:01<00:01, 21.75it/s]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:01<00:01, 21.92it/s]\u001b[A\n",
      "Evaluating:  50% 30/60 [00:01<00:01, 22.07it/s]\u001b[A\n",
      "Evaluating:  55% 33/60 [00:01<00:01, 22.18it/s]\u001b[A\n",
      "Evaluating:  60% 36/60 [00:01<00:01, 22.31it/s]\u001b[A\n",
      "Evaluating:  65% 39/60 [00:01<00:00, 22.39it/s]\u001b[A\n",
      "Evaluating:  70% 42/60 [00:01<00:00, 22.43it/s]\u001b[A\n",
      "Evaluating:  75% 45/60 [00:02<00:00, 22.40it/s]\u001b[A\n",
      "Evaluating:  80% 48/60 [00:02<00:00, 22.44it/s]\u001b[A\n",
      "Evaluating:  85% 51/60 [00:02<00:00, 22.51it/s]\u001b[A\n",
      "Evaluating:  90% 54/60 [00:02<00:00, 22.36it/s]\u001b[A\n",
      "Evaluating:  95% 57/60 [00:02<00:00, 22.37it/s]\u001b[A\n",
      "Evaluating: 100% 60/60 [00:02<00:00, 22.69it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 3000: Eval Loss: 4.5592, PPL: 95.50\n",
      "Epoch 6/8:  64% 364/567 [00:59<00:30,  6.69it/s, total=4.0263, lm=4.0248, orth=0.0015, grad=1.25, tok/s=23246, lr=1.0e-04]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.30it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 16.18it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.13it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.61it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.34it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.85it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 22.10it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.32it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.87it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.01it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.10it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.01it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 20.55it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 20.70it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 20.39it/s]\u001b[A\n",
      "Evaluating:  75% 45/60 [00:02<00:00, 20.08it/s]\u001b[A\n",
      "Evaluating:  78% 47/60 [00:02<00:00, 20.01it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 19.99it/s]\u001b[A\n",
      "Evaluating:  85% 51/60 [00:02<00:00, 19.89it/s]\u001b[A\n",
      "Evaluating:  90% 54/60 [00:02<00:00, 20.21it/s]\u001b[A\n",
      "Evaluating:  95% 57/60 [00:02<00:00, 20.48it/s]\u001b[A\n",
      "Evaluating: 100% 60/60 [00:02<00:00, 21.36it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 3200: Eval Loss: 4.5481, PPL: 94.45\n",
      "Epoch 6/8:  99% 564/567 [01:34<00:00,  6.60it/s, total=4.1192, lm=4.1155, orth=0.0036, grad=1.28, tok/s=23264, lr=7.4e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.07it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.84it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.84it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.25it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.02it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.55it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.86it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.96it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.17it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.44it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.52it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.56it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.05it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.28it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 22.15it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.35it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.50it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.57it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.62it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.73it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 3400: Eval Loss: 4.5387, PPL: 93.57\n",
      "🎯 New best eval loss: 4.5387\n",
      "✅ Saved new best model to checkpoints/best_model.pth.tar\n",
      "Epoch 6/8: 100% 567/567 [01:39<00:00,  5.70it/s, total=3.8147, lm=3.7930, orth=0.0217, grad=2.13, tok/s=23094, lr=7.4e-05]\n",
      "Epoch 6 Summary - Avg Train Loss: 3.9656, Time: 10.1m\n",
      "Epoch 7/8:  35% 197/567 [00:30<00:56,  6.59it/s, total=3.7056, lm=3.7038, orth=0.0018, grad=1.28, tok/s=23234, lr=5.2e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.03it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.74it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.62it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.19it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.01it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.58it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.91it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.19it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.42it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.34it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 22.48it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 22.67it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.82it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.84it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:01<00:00, 22.91it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.87it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.85it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.84it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.81it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.74it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 3600: Eval Loss: 4.5501, PPL: 94.64\n",
      "Epoch 7/8:  70% 397/567 [01:05<00:25,  6.60it/s, total=3.8333, lm=3.8322, orth=0.0011, grad=1.22, tok/s=23254, lr=3.3e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.15it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.95it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.75it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.25it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.97it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.43it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.82it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 22.07it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 21.50it/s]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:01<00:01, 21.09it/s]\u001b[A\n",
      "Evaluating:  50% 30/60 [00:01<00:01, 21.13it/s]\u001b[A\n",
      "Evaluating:  55% 33/60 [00:01<00:01, 20.52it/s]\u001b[A\n",
      "Evaluating:  60% 36/60 [00:01<00:01, 20.65it/s]\u001b[A\n",
      "Evaluating:  63% 38/60 [00:01<00:01, 20.42it/s]\u001b[A\n",
      "Evaluating:  68% 41/60 [00:02<00:00, 20.09it/s]\u001b[A\n",
      "Evaluating:  73% 44/60 [00:02<00:00, 20.32it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 20.23it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 19.99it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 20.31it/s]\u001b[A\n",
      "Evaluating:  90% 54/60 [00:02<00:00, 20.23it/s]\u001b[A\n",
      "Evaluating:  95% 57/60 [00:02<00:00, 20.44it/s]\u001b[A\n",
      "Evaluating: 100% 60/60 [00:02<00:00, 21.35it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 3800: Eval Loss: 4.5450, PPL: 94.16\n",
      "Epoch 7/8: 100% 567/567 [01:34<00:00,  5.98it/s, total=3.8898, lm=3.8832, orth=0.0066, grad=1.93, tok/s=23253, lr=2.0e-05]\n",
      "Epoch 7 Summary - Avg Train Loss: 3.8276, Time: 11.7m\n",
      "Epoch 8/8:   5% 30/567 [00:04<01:20,  6.67it/s, total=3.7277, lm=3.7269, orth=0.0008, grad=1.34, tok/s=23249, lr=1.8e-05]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  6.99it/s]\u001b[A\n",
      "Evaluating:   5% 3/60 [00:00<00:04, 13.37it/s]\u001b[A\n",
      "Evaluating:  10% 6/60 [00:00<00:03, 16.46it/s]\u001b[A\n",
      "Evaluating:  13% 8/60 [00:00<00:03, 17.05it/s]\u001b[A\n",
      "Evaluating:  18% 11/60 [00:00<00:02, 18.67it/s]\u001b[A\n",
      "Evaluating:  23% 14/60 [00:00<00:02, 19.92it/s]\u001b[A\n",
      "Evaluating:  28% 17/60 [00:00<00:02, 20.86it/s]\u001b[A\n",
      "Evaluating:  33% 20/60 [00:01<00:01, 21.46it/s]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:01<00:01, 21.81it/s]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:01<00:01, 21.68it/s]\u001b[A\n",
      "Evaluating:  48% 29/60 [00:01<00:01, 21.70it/s]\u001b[A\n",
      "Evaluating:  53% 32/60 [00:01<00:01, 21.99it/s]\u001b[A\n",
      "Evaluating:  58% 35/60 [00:01<00:01, 22.19it/s]\u001b[A\n",
      "Evaluating:  63% 38/60 [00:01<00:00, 22.25it/s]\u001b[A\n",
      "Evaluating:  68% 41/60 [00:01<00:00, 22.38it/s]\u001b[A\n",
      "Evaluating:  73% 44/60 [00:02<00:00, 22.48it/s]\u001b[A\n",
      "Evaluating:  78% 47/60 [00:02<00:00, 22.14it/s]\u001b[A\n",
      "Evaluating:  83% 50/60 [00:02<00:00, 22.15it/s]\u001b[A\n",
      "Evaluating:  88% 53/60 [00:02<00:00, 22.24it/s]\u001b[A\n",
      "Evaluating:  93% 56/60 [00:02<00:00, 22.26it/s]\u001b[A\n",
      "Evaluating:  98% 59/60 [00:02<00:00, 22.48it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 4000: Eval Loss: 4.5434, PPL: 94.01\n",
      "Epoch 8/8:  41% 230/567 [00:38<00:51,  6.60it/s, total=3.7830, lm=3.7782, orth=0.0047, grad=1.38, tok/s=23280, lr=7.7e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.19it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.97it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 19.03it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.36it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 21.09it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.53it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.81it/s]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:01<00:01, 21.23it/s]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:01<00:01, 20.80it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 20.49it/s]\u001b[A\n",
      "Evaluating:  45% 27/60 [00:01<00:01, 20.24it/s]\u001b[A\n",
      "Evaluating:  50% 30/60 [00:01<00:01, 20.45it/s]\u001b[A\n",
      "Evaluating:  53% 32/60 [00:01<00:01, 20.30it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 20.18it/s]\u001b[A\n",
      "Evaluating:  60% 36/60 [00:01<00:01, 19.90it/s]\u001b[A\n",
      "Evaluating:  65% 39/60 [00:01<00:01, 20.91it/s]\u001b[A\n",
      "Evaluating:  70% 42/60 [00:02<00:00, 21.19it/s]\u001b[A\n",
      "Evaluating:  75% 45/60 [00:02<00:00, 21.62it/s]\u001b[A\n",
      "Evaluating:  80% 48/60 [00:02<00:00, 21.84it/s]\u001b[A\n",
      "Evaluating:  85% 51/60 [00:02<00:00, 22.08it/s]\u001b[A\n",
      "Evaluating:  88% 53/60 [00:02<00:00, 21.54it/s]\u001b[A\n",
      "Evaluating:  93% 56/60 [00:02<00:00, 21.84it/s]\u001b[A\n",
      "Evaluating:  98% 59/60 [00:02<00:00, 22.15it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 4200: Eval Loss: 4.5451, PPL: 94.17\n",
      "Epoch 8/8:  76% 430/567 [01:13<00:20,  6.54it/s, total=3.7928, lm=3.7920, orth=0.0008, grad=1.27, tok/s=23301, lr=2.1e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.14it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.92it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.97it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.26it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.46it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 21.11it/s]\u001b[A\n",
      "Evaluating:  32% 19/60 [00:00<00:01, 21.65it/s]\u001b[A\n",
      "Evaluating:  37% 22/60 [00:01<00:01, 21.89it/s]\u001b[A\n",
      "Evaluating:  42% 25/60 [00:01<00:01, 22.15it/s]\u001b[A\n",
      "Evaluating:  47% 28/60 [00:01<00:01, 22.28it/s]\u001b[A\n",
      "Evaluating:  52% 31/60 [00:01<00:01, 21.75it/s]\u001b[A\n",
      "Evaluating:  57% 34/60 [00:01<00:01, 21.90it/s]\u001b[A\n",
      "Evaluating:  62% 37/60 [00:01<00:01, 22.03it/s]\u001b[A\n",
      "Evaluating:  67% 40/60 [00:01<00:00, 22.10it/s]\u001b[A\n",
      "Evaluating:  72% 43/60 [00:02<00:00, 21.96it/s]\u001b[A\n",
      "Evaluating:  77% 46/60 [00:02<00:00, 22.07it/s]\u001b[A\n",
      "Evaluating:  82% 49/60 [00:02<00:00, 22.04it/s]\u001b[A\n",
      "Evaluating:  87% 52/60 [00:02<00:00, 22.18it/s]\u001b[A\n",
      "Evaluating:  92% 55/60 [00:02<00:00, 22.11it/s]\u001b[A\n",
      "Evaluating:  97% 58/60 [00:02<00:00, 22.27it/s]\u001b[A\n",
      "Evaluating: 100% 60/60 [00:02<00:00, 21.41it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 4400: Eval Loss: 4.5464, PPL: 94.30\n",
      "Epoch 8/8: 100% 566/567 [01:38<00:00,  6.60it/s, total=3.7471, lm=3.7391, orth=0.0080, grad=1.74, tok/s=23270, lr=1.0e-06]\n",
      "Evaluating:   0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2% 1/60 [00:00<00:08,  7.12it/s]\u001b[A\n",
      "Evaluating:   7% 4/60 [00:00<00:03, 15.91it/s]\u001b[A\n",
      "Evaluating:  12% 7/60 [00:00<00:02, 18.75it/s]\u001b[A\n",
      "Evaluating:  17% 10/60 [00:00<00:02, 20.01it/s]\u001b[A\n",
      "Evaluating:  22% 13/60 [00:00<00:02, 20.73it/s]\u001b[A\n",
      "Evaluating:  27% 16/60 [00:00<00:02, 20.23it/s]\u001b[A\n",
      "Evaluating:  30% 18/60 [00:00<00:02, 20.15it/s]\u001b[A\n",
      "Evaluating:  35% 21/60 [00:01<00:01, 20.43it/s]\u001b[A\n",
      "Evaluating:  38% 23/60 [00:01<00:01, 20.27it/s]\u001b[A\n",
      "Evaluating:  43% 26/60 [00:01<00:01, 19.93it/s]\u001b[A\n",
      "Evaluating:  48% 29/60 [00:01<00:01, 20.30it/s]\u001b[A\n",
      "Evaluating:  53% 32/60 [00:01<00:01, 20.81it/s]\u001b[A\n",
      "Evaluating:  58% 35/60 [00:01<00:01, 21.14it/s]\u001b[A\n",
      "Evaluating:  63% 38/60 [00:01<00:01, 21.34it/s]\u001b[A\n",
      "Evaluating:  68% 41/60 [00:02<00:00, 21.53it/s]\u001b[A\n",
      "Evaluating:  73% 44/60 [00:02<00:00, 21.75it/s]\u001b[A\n",
      "Evaluating:  78% 47/60 [00:02<00:00, 21.90it/s]\u001b[A\n",
      "Evaluating:  83% 50/60 [00:02<00:00, 22.00it/s]\u001b[A\n",
      "Evaluating:  88% 53/60 [00:02<00:00, 21.32it/s]\u001b[A\n",
      "Evaluating:  93% 56/60 [00:02<00:00, 21.26it/s]\u001b[A\n",
      "Evaluating:  98% 59/60 [00:02<00:00, 21.75it/s]\u001b[A\n",
      "                                               \u001b[A\n",
      "📈 Step 4536: Eval Loss: 4.5458, PPL: 94.24\n",
      "Epoch 8/8: 100% 567/567 [01:42<00:00,  5.53it/s, total=3.7471, lm=3.7391, orth=0.0080, grad=1.74, tok/s=23270, lr=1.0e-06]\n",
      "Epoch 8 Summary - Avg Train Loss: 3.7633, Time: 13.4m\n",
      "\n",
      "✅ GNN-MoE Training Complete!\n",
      "🎯 Best eval loss during this run: 4.5387\n",
      "⏱️ Total time for this run: 13.4 minutes\n",
      "📊 Training results plot saved to plots/training_results.png\n",
      "🔄 Loading best model from checkpoints/best_model.pth.tar for final analysis...\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "Using GNNExpertCoupler for MoE layer.\n",
      "🔄 Loading checkpoint from 'checkpoints/best_model.pth.tar'\n",
      "✅ Checkpoint loaded. Resuming from epoch 6, step 3400, best_eval_loss 4.5387\n",
      "\n",
      "🧠 Expert Communication Analysis\n",
      "\n",
      "LAYER_0:\n",
      "  GNN Layer 1 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.400, Max: 0.710\n",
      "  GNN Layer 2 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.420, Max: 0.751\n",
      "\n",
      "LAYER_1:\n",
      "  GNN Layer 1 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.411, Max: 0.687\n",
      "  GNN Layer 2 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.481, Max: 0.746\n",
      "\n",
      "LAYER_2:\n",
      "  GNN Layer 1 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.432, Max: 0.805\n",
      "  GNN Layer 2 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.553, Max: 0.843\n",
      "\n",
      "LAYER_3:\n",
      "  GNN Layer 1 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.581, Max: 0.865\n",
      "  GNN Layer 2 - Expert connectivity (Adjacency Strength):\n",
      "    Avg connectivity: 0.516, Max: 0.909\n",
      "🎨 Expert connectivity plot saved to plots/expert_connectivity.png\n",
      "\n",
      "⚡ GNN-MoE Efficiency Analysis\n",
      "  Total Parameters: 39,773,401\n",
      "  Expert Parameters: 12,636,160 (31.8%)\n",
      "  GNN Coord Params: 1,322,120 (3.3%)\n",
      "  Other (Embeds, etc.): 25,815,121 (64.9%)\n",
      "  Expert Utilization: ALL 4 experts active per layer.\n",
      "  GNN Coordination: 2 GNN layers per expert group.\n",
      "\n",
      "🎉 GNN-MoE Hyperparameter Script Execution Finished Successfully!\n",
      "   Run Name: default_run\n",
      "   Data Mode: REAL_WIKITEXT_2_V1\n",
      "   Best Eval Loss from run: 4.5387\n",
      "   Best Eval Perplexity from run: 93.57\n",
      "==============================================\n",
      "📝 Run summary saved to checkpoints/run_summary.json\n"
     ]
    }
   ],
   "source": [
    "!python run_gnn_moe.py \\\n",
    "  --apply_weight_orthogonality_loss \\\n",
    "  --weight_orthogonality_loss_weight 0.05 \\\n",
    "  --weight_orthogonality_target_layer ffn_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BUcVIgjRlGk",
    "outputId": "dd717083-86af-4307-b4cf-35981246a2af",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_gnn_moe.py [-h] [--embed_dim EMBED_DIM] [--num_layers NUM_LAYERS]\n",
      "                      [--num_heads NUM_HEADS] [--dropout_rate DROPOUT_RATE]\n",
      "                      [--num_experts NUM_EXPERTS] [--gnn_layers GNN_LAYERS]\n",
      "                      [--batch_size BATCH_SIZE]\n",
      "                      [--learning_rate LEARNING_RATE] [--epochs EPOCHS]\n",
      "                      [--max_batches_per_epoch MAX_BATCHES_PER_EPOCH]\n",
      "                      [--eval_every EVAL_EVERY] [--dataset_name DATASET_NAME]\n",
      "                      [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                      [--num_train_samples NUM_TRAIN_SAMPLES]\n",
      "                      [--num_eval_samples NUM_EVAL_SAMPLES]\n",
      "                      [--checkpoint_dir CHECKPOINT_DIR]\n",
      "                      [--resume_checkpoint RESUME_CHECKPOINT]\n",
      "                      [--run_name RUN_NAME] [--seed SEED]\n",
      "                      [--num_workers_dataloader NUM_WORKERS_DATALOADER]\n",
      "                      [--quiet]\n",
      "run_gnn_moe.py: error: unrecognized arguments: --apply_orthogonality_loss --apply_weight_orthogonality_loss --combine_weight_output_orthogonality --weight_orthogonality_target_layer combined\n"
     ]
    }
   ],
   "source": [
    "!python3 run_gnn_moe.py \\\n",
    "  --apply_orthogonality_loss \\\n",
    "  --apply_weight_orthogonality_loss \\\n",
    "  --combine_weight_output_orthogonality \\\n",
    "  --weight_orthogonality_target_layer combined \\\n",
    "  --dataset_config_name wikitext-2-v1 \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdUks0BsY2sT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
